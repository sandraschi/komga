# AI-Powered Extensions for Komga

This section details the advanced Artificial Intelligence (AI) and Machine Learning (ML) extensions integrated into this fork of Komga. These features aim to significantly enhance book discovery, analysis, and interaction by leveraging Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) techniques.

Our goal is to be at the forefront of integrating modern AI capabilities into the digital library experience, providing users with powerful new ways to engage with their content.

## Documentation Structure

This documentation is organized into the following parts, detailing the various components and aspects of the AI extensions:

1.  **[Part 1: LLM Integration](./chunk_01_llm_integration.md)**
    *   Overview of Local and Cloud LLM Support
    *   Supported LLM Providers and Configuration
    *   LLM-Related UI Components and User Interactions (Current and Planned)

2.  **[Part 2: RAG Architecture and Implementation](./chunk_02_rag_architecture.md)**
    *   Current State of the RAG System
    *   Core RAG Tools, Pipeline (Document Processing, Embedding)
    *   RAG-Related UI Components (e.g., Semantic Search Interface)

3.  **[Part 3: Data Backend and Semantic Search](./chunk_03_data_and_search.md)**
    *   Vector Database Usage (e.g., ChromaDB)
    *   Text Chunking Strategies and Implementation
    *   Semantic Search Capabilities and LLM-Powered Query Enhancements

4.  **[Part 4: Development Status and Testing](./chunk_04_development_status.md)**
    *   Current Build Status of AI Features
    *   Identified Missing Parts, Components, or Known Issues
    *   Test Scaffolding, Testing Strategies, and Tools Used

5.  **[Part 5: Future Directions and Vision](./chunk_05_future_directions.md)**
    *   Planned Enhancements and Roadmap for AI Features
    *   Long-term Vision for AI in Komga

Dive into these sections to understand the current capabilities, underlying technologies, and future potential of AI within this Komga fork.
